{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo 17.1 Participación en el mercado laboral de las mujeres casadas (mroz.dta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inlf</th>\n",
       "      <th>hours</th>\n",
       "      <th>kidslt6</th>\n",
       "      <th>kidsge6</th>\n",
       "      <th>age</th>\n",
       "      <th>educ</th>\n",
       "      <th>wage</th>\n",
       "      <th>repwage</th>\n",
       "      <th>hushrs</th>\n",
       "      <th>husage</th>\n",
       "      <th>...</th>\n",
       "      <th>faminc</th>\n",
       "      <th>mtr</th>\n",
       "      <th>motheduc</th>\n",
       "      <th>fatheduc</th>\n",
       "      <th>unem</th>\n",
       "      <th>city</th>\n",
       "      <th>exper</th>\n",
       "      <th>nwifeinc</th>\n",
       "      <th>lwage</th>\n",
       "      <th>expersq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1610</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>12</td>\n",
       "      <td>3.3540</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2708</td>\n",
       "      <td>34</td>\n",
       "      <td>...</td>\n",
       "      <td>16310.0</td>\n",
       "      <td>0.7215</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>10.910060</td>\n",
       "      <td>1.210154</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1656</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>1.3889</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2310</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>21800.0</td>\n",
       "      <td>0.6615</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>19.499981</td>\n",
       "      <td>0.328512</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1980</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>12</td>\n",
       "      <td>4.5455</td>\n",
       "      <td>4.04</td>\n",
       "      <td>3072</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>21040.0</td>\n",
       "      <td>0.6915</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>12.039910</td>\n",
       "      <td>1.514138</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>456</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0965</td>\n",
       "      <td>3.25</td>\n",
       "      <td>1920</td>\n",
       "      <td>53</td>\n",
       "      <td>...</td>\n",
       "      <td>7300.0</td>\n",
       "      <td>0.7815</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6.799996</td>\n",
       "      <td>0.092123</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1568</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>14</td>\n",
       "      <td>4.5918</td>\n",
       "      <td>3.60</td>\n",
       "      <td>2000</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>27300.0</td>\n",
       "      <td>0.6215</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>9.5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>20.100058</td>\n",
       "      <td>1.524272</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   inlf  hours  kidslt6  kidsge6  age  educ    wage  repwage  hushrs  husage  \\\n",
       "0     1   1610        1        0   32    12  3.3540     2.65    2708      34   \n",
       "1     1   1656        0        2   30    12  1.3889     2.65    2310      30   \n",
       "2     1   1980        1        3   35    12  4.5455     4.04    3072      40   \n",
       "3     1    456        0        3   34    12  1.0965     3.25    1920      53   \n",
       "4     1   1568        1        2   31    14  4.5918     3.60    2000      32   \n",
       "\n",
       "   ...   faminc     mtr  motheduc  fatheduc  unem  city  exper   nwifeinc  \\\n",
       "0  ...  16310.0  0.7215        12         7   5.0     0     14  10.910060   \n",
       "1  ...  21800.0  0.6615         7         7  11.0     1      5  19.499981   \n",
       "2  ...  21040.0  0.6915        12         7   5.0     0     15  12.039910   \n",
       "3  ...   7300.0  0.7815         7         7   5.0     0      6   6.799996   \n",
       "4  ...  27300.0  0.6215        12        14   9.5     1      7  20.100058   \n",
       "\n",
       "      lwage  expersq  \n",
       "0  1.210154      196  \n",
       "1  0.328512       25  \n",
       "2  1.514138      225  \n",
       "3  0.092123       36  \n",
       "4  1.524272       49  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_stata('mroz.dta')\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   inlf   R-squared:                       0.264\n",
      "Model:                            OLS   Adj. R-squared:                  0.257\n",
      "Method:                 Least Squares   F-statistic:                     38.22\n",
      "Date:                Tue, 08 Oct 2019   Prob (F-statistic):           6.90e-46\n",
      "Time:                        21:17:53   Log-Likelihood:                -423.89\n",
      "No. Observations:                 753   AIC:                             863.8\n",
      "Df Residuals:                     745   BIC:                             900.8\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      0.5855      0.154      3.798      0.000       0.283       0.888\n",
      "nwifeinc      -0.0034      0.001     -2.351      0.019      -0.006      -0.001\n",
      "educ           0.0380      0.007      5.151      0.000       0.024       0.052\n",
      "exper          0.0395      0.006      6.962      0.000       0.028       0.051\n",
      "expersq       -0.0006      0.000     -3.227      0.001      -0.001      -0.000\n",
      "age           -0.0161      0.002     -6.476      0.000      -0.021      -0.011\n",
      "kidslt6       -0.2618      0.034     -7.814      0.000      -0.328      -0.196\n",
      "kidsge6        0.0130      0.013      0.986      0.324      -0.013       0.039\n",
      "==============================================================================\n",
      "Omnibus:                      169.137   Durbin-Watson:                   0.494\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               36.741\n",
      "Skew:                          -0.196   Prob(JB):                     1.05e-08\n",
      "Kurtosis:                       1.991   Cond. No.                     3.06e+03\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 3.06e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "reg1 = smf.ols('inlf ~ nwifeinc + educ + exper + expersq +age+kidslt6+ kidsge6', data = df1).fit()\n",
    "print(reg1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como ejemplo de interpretación, si seaumenta la educación en un año, , ceteris paribuis, la probabilidad para la mujer \n",
    "# de participar en el mercado de trabajo , aumenta en 0,038\n",
    "# El aumento de una unidad de otros ingresos (nwideinc) la probabilidad de la mujer para participar en el mercado de \n",
    "# trabajo disminuye en 0,0034, ceteris paribus,  que es un coeficiente bajo , pero es estadísticamente significativo\n",
    "# Al aumentar la experiencia en un año, la probabildiad de la mujer para participar en el mercado de trabajo aumenta \n",
    "# en 0,039 – 2 * (0,0006)exper\n",
    "# El punto en que la experiencia no afecta la probabilidad  participar en el mercado de trabajo, que es cuando cambia de \n",
    "# pendiente, es 0,039/0,0012 = 32,5 . Solo hay 13 mujeres con  exper > 32\n",
    "# Al aumentar la edad un año, ceteris paribus, la probabilidad de la mujer de participar enel mercado de trabajo se reduce \n",
    "# en  0,016\n",
    "# Tener un hijo  adicional de menos de 6 años, ceteris paribus, reduce la probabilidad de participar en 0,262\n",
    "# Tener un hijo entre 6 y 18 años adicional, ceteris paribus, aumeta la probabilidad de la mujer de participar en el mercado\n",
    "# de trabajo en 0,013\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.533553\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                   inlf   No. Observations:                  753\n",
      "Model:                          Logit   Df Residuals:                      745\n",
      "Method:                           MLE   Df Model:                            7\n",
      "Date:                Tue, 08 Oct 2019   Pseudo R-squ.:                  0.2197\n",
      "Time:                        21:17:53   Log-Likelihood:                -401.77\n",
      "converged:                       True   LL-Null:                       -514.87\n",
      "                                        LLR p-value:                 3.159e-45\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      0.4255      0.860      0.494      0.621      -1.261       2.112\n",
      "nwifeinc      -0.0213      0.008     -2.535      0.011      -0.038      -0.005\n",
      "educ           0.2212      0.043      5.091      0.000       0.136       0.306\n",
      "exper          0.2059      0.032      6.422      0.000       0.143       0.269\n",
      "expersq       -0.0032      0.001     -3.104      0.002      -0.005      -0.001\n",
      "age           -0.0880      0.015     -6.040      0.000      -0.117      -0.059\n",
      "kidslt6       -1.4434      0.204     -7.090      0.000      -1.842      -1.044\n",
      "kidsge6        0.0601      0.075      0.804      0.422      -0.086       0.207\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "reg2 = smf.logit('inlf ~ nwifeinc + educ + exper + expersq +age+kidslt6+ kidsge6', data = df1).fit()\n",
    "print(reg2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.20973456, 0.18800195, 0.20918232, 0.17372607, 0.24341655,\n",
       "       0.15155625, 0.06921232, 0.15531693, 0.12797552, 0.07479226,\n",
       "       0.0976142 , 0.19064808, 0.17746039, 0.16185309, 0.23546894,\n",
       "       0.17971209, 0.10745401, 0.21939012, 0.11453204, 0.13822804,\n",
       "       0.20941053, 0.09352016, 0.16001609, 0.16899973, 0.23847946,\n",
       "       0.05082137, 0.20589884, 0.13264094, 0.19865055, 0.2431598 ,\n",
       "       0.13007686, 0.24459843, 0.07323989, 0.23204923, 0.04180409,\n",
       "       0.18908936, 0.15884414, 0.1309055 , 0.11782347, 0.04301659,\n",
       "       0.19545411, 0.24871709, 0.23177698, 0.2447791 , 0.15493556,\n",
       "       0.20780808, 0.18256281, 0.10753179, 0.22010665, 0.14489354,\n",
       "       0.23361218, 0.19454972, 0.08048576, 0.24999943, 0.17382002,\n",
       "       0.06626962, 0.13233766, 0.07059131, 0.13898737, 0.22715783,\n",
       "       0.0797646 , 0.20048991, 0.24156616, 0.19029938, 0.14173264,\n",
       "       0.21575675, 0.09351909, 0.13618627, 0.21429134, 0.15961958,\n",
       "       0.11011316, 0.24965376, 0.24168628, 0.1647638 , 0.07748378,\n",
       "       0.15296742, 0.24046292, 0.05343388, 0.23295564, 0.14025014,\n",
       "       0.24942676, 0.16652564, 0.24932558, 0.21284117, 0.1780084 ,\n",
       "       0.07866299, 0.17725528, 0.19343077, 0.24692982, 0.24655654,\n",
       "       0.15640499, 0.17847828, 0.22980284, 0.23404774, 0.08177852,\n",
       "       0.1125696 , 0.1222005 , 0.23818407, 0.24128619, 0.24542543,\n",
       "       0.24984594, 0.13169026, 0.1748845 , 0.24816286, 0.2189734 ,\n",
       "       0.17314123, 0.15784394, 0.11340593, 0.13402991, 0.24745725,\n",
       "       0.23788275, 0.13361844, 0.13055402, 0.22437312, 0.22382689,\n",
       "       0.18867479, 0.12709061, 0.23741066, 0.09254047, 0.23318021,\n",
       "       0.21695053, 0.09640174, 0.24675744, 0.13187779, 0.19444873,\n",
       "       0.08113718, 0.23770196, 0.20911182, 0.21314799, 0.2461891 ,\n",
       "       0.16798686, 0.09481173, 0.14534769, 0.19603945, 0.18299262,\n",
       "       0.22394775, 0.24330491, 0.17497931, 0.19647673, 0.16657105,\n",
       "       0.19738877, 0.05660299, 0.05199596, 0.13824561, 0.20137679,\n",
       "       0.24005631, 0.22230748, 0.13061653, 0.22527006, 0.05066907,\n",
       "       0.08380415, 0.19890943, 0.24505026, 0.19659097, 0.23658345,\n",
       "       0.24503529, 0.24197358, 0.04796509, 0.08820678, 0.12346718,\n",
       "       0.08395124, 0.11808631, 0.04397593, 0.22227944, 0.14034693,\n",
       "       0.24162092, 0.05265845, 0.20446545, 0.24593842, 0.10317661,\n",
       "       0.23842394, 0.19501725, 0.10598421, 0.21807397, 0.12237233,\n",
       "       0.16779838, 0.1108765 , 0.09805056, 0.22495414, 0.24672679,\n",
       "       0.12750342, 0.23025338, 0.19235888, 0.16285484, 0.24140952,\n",
       "       0.22552876, 0.05791859, 0.21373968, 0.17055269, 0.11653355,\n",
       "       0.21266923, 0.17720437, 0.22519108, 0.13730206, 0.22295225,\n",
       "       0.22993848, 0.0697067 , 0.23964487, 0.16180888, 0.24272729,\n",
       "       0.23420498, 0.24206212, 0.07305425, 0.24855072, 0.13207645,\n",
       "       0.17662785, 0.17500856, 0.07889218, 0.21485709, 0.17895159,\n",
       "       0.13429552, 0.23445207, 0.20934463, 0.24195274, 0.13567494,\n",
       "       0.19338227, 0.16932752, 0.08849167, 0.11345521, 0.11391832,\n",
       "       0.12314553, 0.249836  , 0.24984758, 0.15707824, 0.09152408,\n",
       "       0.17558159, 0.24254697, 0.24317863, 0.19555626, 0.22985021,\n",
       "       0.14703879, 0.23068192, 0.23662849, 0.2115201 , 0.0744396 ,\n",
       "       0.24878224, 0.09973189, 0.2182914 , 0.10337425, 0.10304582,\n",
       "       0.16446114, 0.09759735, 0.11875461, 0.22182892, 0.23211396,\n",
       "       0.2472015 , 0.2499952 , 0.23372328, 0.16886028, 0.20023313,\n",
       "       0.16454225, 0.16413498, 0.14266882, 0.17294198, 0.15071452,\n",
       "       0.2337774 , 0.23705168, 0.24463432, 0.24772808, 0.15948078,\n",
       "       0.11924687, 0.17375553, 0.10096656, 0.2287309 , 0.24938999,\n",
       "       0.23179385, 0.24489223, 0.24005008, 0.24602799, 0.24638382,\n",
       "       0.15167328, 0.23420123, 0.24716518, 0.15814438, 0.24798894,\n",
       "       0.10415455, 0.15064713, 0.24982717, 0.09416533, 0.05170408,\n",
       "       0.08641601, 0.21273275, 0.21411588, 0.23541862, 0.15347311,\n",
       "       0.2167432 , 0.24908997, 0.07704546, 0.14223147, 0.18834067,\n",
       "       0.09479877, 0.07927682, 0.16468444, 0.15703753, 0.11545503,\n",
       "       0.15566948, 0.0914425 , 0.14287324, 0.15930961, 0.03046912,\n",
       "       0.11167377, 0.08614559, 0.24285777, 0.05537894, 0.23335012,\n",
       "       0.20212547, 0.11509279, 0.17781963, 0.24792014, 0.23077123,\n",
       "       0.1522776 , 0.08844076, 0.09666606, 0.14474296, 0.06561834,\n",
       "       0.23690455, 0.16422939, 0.24902226, 0.24991421, 0.18026444,\n",
       "       0.22538854, 0.22933315, 0.24344174, 0.19526745, 0.08056162,\n",
       "       0.22149669, 0.23408309, 0.24168591, 0.17697459, 0.08764176,\n",
       "       0.08095013, 0.0548139 , 0.17443944, 0.20083504, 0.2322994 ,\n",
       "       0.06979689, 0.20556783, 0.23937343, 0.08155842, 0.16021817,\n",
       "       0.22007234, 0.23559119, 0.09042387, 0.16827137, 0.04932949,\n",
       "       0.2499492 , 0.10399633, 0.16635788, 0.10991425, 0.11270677,\n",
       "       0.14922319, 0.24695373, 0.22601259, 0.08051381, 0.16593477,\n",
       "       0.2427011 , 0.0681605 , 0.24224839, 0.18054276, 0.10012864,\n",
       "       0.2328153 , 0.16748861, 0.19654062, 0.24556529, 0.11414863,\n",
       "       0.22141829, 0.20552111, 0.13276769, 0.11607885, 0.18217719,\n",
       "       0.10765239, 0.24200405, 0.09358935, 0.192119  , 0.24984866,\n",
       "       0.20527376, 0.2498487 , 0.09200982, 0.17472093, 0.23769556,\n",
       "       0.08345085, 0.13034291, 0.07583396, 0.12903255, 0.0707859 ,\n",
       "       0.15631637, 0.24222287, 0.22589352, 0.07265938, 0.09920658,\n",
       "       0.20240358, 0.04781634, 0.24608217, 0.2236864 , 0.17428737,\n",
       "       0.23789391, 0.24991043, 0.05525971, 0.22185231, 0.24812695,\n",
       "       0.23790144, 0.05259651, 0.14844225, 0.23544069, 0.12570636,\n",
       "       0.08048079, 0.13643764, 0.19408808, 0.08322612, 0.22282042,\n",
       "       0.0904934 , 0.24610995, 0.08678439, 0.09501817, 0.24982474,\n",
       "       0.14006263, 0.1816796 , 0.24367757, 0.06752962, 0.24978494,\n",
       "       0.22007822, 0.18041486, 0.23911638, 0.24698517, 0.09967348,\n",
       "       0.09150283, 0.10607743, 0.15448416, 0.17567065, 0.18581823,\n",
       "       0.23353586, 0.20953334, 0.21932294, 0.24940323, 0.22882431,\n",
       "       0.20277229, 0.18810914, 0.24996077, 0.14499479, 0.14595238,\n",
       "       0.09605106, 0.20018521, 0.06579626, 0.24430466, 0.24696706,\n",
       "       0.22338305, 0.12905839, 0.21698266, 0.16530551, 0.24333814,\n",
       "       0.20755552, 0.20949756, 0.2021235 , 0.23853399, 0.24990235,\n",
       "       0.24998582, 0.23248245, 0.24967691, 0.11992347, 0.24129099,\n",
       "       0.24366698, 0.12064879, 0.19813827, 0.2241333 , 0.15074397,\n",
       "       0.24978547, 0.23762143, 0.2472417 , 0.23207433, 0.07803076,\n",
       "       0.23781614, 0.2470992 , 0.11551784, 0.16518135, 0.08475949,\n",
       "       0.13922394, 0.24889186, 0.2499897 , 0.22965316, 0.23249854,\n",
       "       0.24856141, 0.24983036, 0.06910662, 0.00911077, 0.05709708,\n",
       "       0.17772785, 0.05066719, 0.22503558, 0.13443957, 0.19051313,\n",
       "       0.15783797, 0.15886039, 0.24999996, 0.18757083, 0.22120205,\n",
       "       0.20066347, 0.07736106, 0.10491601, 0.24122712, 0.23754375,\n",
       "       0.17850983, 0.10561981, 0.17687414, 0.12189501, 0.16484035,\n",
       "       0.15485025, 0.22893262, 0.23489133, 0.19902393, 0.18865855,\n",
       "       0.12403213, 0.17191756, 0.24877033, 0.0485532 , 0.21098675,\n",
       "       0.16087175, 0.19677446, 0.15229543, 0.21088276, 0.20311626,\n",
       "       0.24089697, 0.12920013, 0.21199702, 0.24744306, 0.21640753,\n",
       "       0.13588617, 0.23481509, 0.1344338 , 0.17988948, 0.21257958,\n",
       "       0.00859725, 0.1140153 , 0.18843241, 0.24959516, 0.24645013,\n",
       "       0.13236193, 0.16227541, 0.24880961, 0.20734521, 0.2487796 ,\n",
       "       0.2499756 , 0.24982465, 0.1562198 , 0.24877995, 0.21589485,\n",
       "       0.24926185, 0.18920391, 0.1708679 , 0.24363866, 0.24172613,\n",
       "       0.1683045 , 0.14742691, 0.06027352, 0.1569689 , 0.24456597,\n",
       "       0.23445416, 0.21365344, 0.15649218, 0.17342409, 0.24995585,\n",
       "       0.21213287, 0.03059119, 0.24061015, 0.21938998, 0.24998653,\n",
       "       0.24998687, 0.1450307 , 0.22222566, 0.22972789, 0.20365549,\n",
       "       0.24698936, 0.21260243, 0.15102126, 0.24973664, 0.20199178,\n",
       "       0.18188654, 0.19954742, 0.23724032, 0.12510313, 0.05757847,\n",
       "       0.17458245, 0.22640063, 0.18976359, 0.16370733, 0.18439371,\n",
       "       0.02536968, 0.17242412, 0.22063585, 0.24710262, 0.23446653,\n",
       "       0.07950006, 0.24999982, 0.0506241 , 0.10283255, 0.18353591,\n",
       "       0.02322328, 0.23847047, 0.24978222, 0.1898782 , 0.18571607,\n",
       "       0.17946694, 0.16560793, 0.22609042, 0.18538021, 0.02540786,\n",
       "       0.24674312, 0.19571736, 0.23084886, 0.24994135, 0.24857988,\n",
       "       0.18355055, 0.24632135, 0.20663952, 0.18039102, 0.23878805,\n",
       "       0.21462565, 0.07661288, 0.11832814, 0.0875811 , 0.19002502,\n",
       "       0.0527709 , 0.21477839, 0.20983113, 0.15909697, 0.2495201 ,\n",
       "       0.22373258, 0.15130834, 0.22644558, 0.06753588, 0.149556  ,\n",
       "       0.21847645, 0.15789167, 0.19496799, 0.17999655, 0.24933232,\n",
       "       0.16347558, 0.1901417 , 0.24928512, 0.21699285, 0.05341444,\n",
       "       0.05927627, 0.11096739, 0.07606259, 0.16503355, 0.22743845,\n",
       "       0.20395907, 0.10684044, 0.19369711, 0.122299  , 0.03888837,\n",
       "       0.23837371, 0.23703546, 0.19105188, 0.23005186, 0.17909377,\n",
       "       0.21238301, 0.10438615, 0.15578359, 0.24022857, 0.16441801,\n",
       "       0.13424897, 0.24282462, 0.24689954, 0.1954079 , 0.24808448,\n",
       "       0.23809751, 0.15145117, 0.17948785, 0.20421346, 0.21970457,\n",
       "       0.23102088, 0.24604299, 0.21612787, 0.24957674, 0.12313777,\n",
       "       0.14336974, 0.02320416, 0.24267984, 0.22864644, 0.17631767,\n",
       "       0.23661258, 0.21926892, 0.23975771, 0.240356  , 0.21746168,\n",
       "       0.19515132, 0.24387889, 0.14406751, 0.03463156, 0.20468503,\n",
       "       0.24813169, 0.08949694, 0.18780411, 0.22024772, 0.23372197,\n",
       "       0.15786974, 0.16195696, 0.15080937, 0.21848534, 0.2233637 ,\n",
       "       0.22344411, 0.22466496, 0.24956248, 0.14466225, 0.24716297,\n",
       "       0.24296577, 0.09910242, 0.24782064, 0.22426866, 0.15940968,\n",
       "       0.20765169, 0.21050552, 0.20636279, 0.12562221, 0.0295938 ,\n",
       "       0.23594664, 0.24512438, 0.24557801, 0.08029423, 0.17677693,\n",
       "       0.23085994, 0.17395089, 0.22693072, 0.10421472, 0.1477712 ,\n",
       "       0.18747727, 0.19733097, 0.23215361, 0.17840469, 0.2367552 ,\n",
       "       0.24958507, 0.18653657, 0.1755241 , 0.10637697, 0.2427887 ,\n",
       "       0.24727257, 0.18730265, 0.19974412, 0.24727986, 0.20470613,\n",
       "       0.22706396, 0.22552805, 0.23604197, 0.24872989, 0.21148928,\n",
       "       0.0974731 , 0.17322208, 0.2224486 , 0.24618054, 0.24427072,\n",
       "       0.24869114, 0.2422056 , 0.23047492])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import logistic\n",
    "logistic.pdf(reg2.fittedvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17857963439562646"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(logistic.pdf(reg2.fittedvalues))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Logit Marginal Effects       \n",
      "=====================================\n",
      "Dep. Variable:                   inlf\n",
      "Method:                          dydx\n",
      "At:                           overall\n",
      "==============================================================================\n",
      "                dy/dx    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "nwifeinc      -0.0038      0.001     -2.571      0.010      -0.007      -0.001\n",
      "educ           0.0395      0.007      5.414      0.000       0.025       0.054\n",
      "exper          0.0368      0.005      7.139      0.000       0.027       0.047\n",
      "expersq       -0.0006      0.000     -3.176      0.001      -0.001      -0.000\n",
      "age           -0.0157      0.002     -6.603      0.000      -0.020      -0.011\n",
      "kidslt6       -0.2578      0.032     -8.070      0.000      -0.320      -0.195\n",
      "kidsge6        0.0107      0.013      0.805      0.421      -0.015       0.037\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "margeff = reg2.get_margeff()\n",
    "print(margeff.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.532938\n",
      "         Iterations 5\n",
      "                          Probit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                   inlf   No. Observations:                  753\n",
      "Model:                         Probit   Df Residuals:                      745\n",
      "Method:                           MLE   Df Model:                            7\n",
      "Date:                Tue, 08 Oct 2019   Pseudo R-squ.:                  0.2206\n",
      "Time:                        21:19:22   Log-Likelihood:                -401.30\n",
      "converged:                       True   LL-Null:                       -514.87\n",
      "                                        LLR p-value:                 2.009e-45\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      0.2701      0.509      0.531      0.595      -0.727       1.267\n",
      "nwifeinc      -0.0120      0.005     -2.484      0.013      -0.022      -0.003\n",
      "educ           0.1309      0.025      5.183      0.000       0.081       0.180\n",
      "exper          0.1233      0.019      6.590      0.000       0.087       0.160\n",
      "expersq       -0.0019      0.001     -3.145      0.002      -0.003      -0.001\n",
      "age           -0.0529      0.008     -6.235      0.000      -0.069      -0.036\n",
      "kidslt6       -0.8683      0.119     -7.326      0.000      -1.101      -0.636\n",
      "kidsge6        0.0360      0.043      0.828      0.408      -0.049       0.121\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "reg3 = smf.probit('inlf ~ nwifeinc + educ + exper + expersq +age+kidslt6+ kidsge6', data = df1).fit()\n",
    "print(reg3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para cuantificar e interpretar los efectos marginales, sobre la probabilidad de participación en el mercado de trabajo de la\n",
    "# mujer, debemos tener presente que en el modelo Prbit el efcto marginal de la variable  Xj es \n",
    "# dP(Y = 1|X)/dXj = g(XB) Bj\n",
    "# Es decir, es el coeficiente estimado Bj multiplicado por el valor de la normal en la regresión estimada para  los \n",
    "# valores específicos de las variables  explicativas\n",
    "# Es decir que tenemos 753 efectos marginales, uno para cada individuo de la muestra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para crear la serie de lso efectos marginales de cada individuo lo que tenemos que hace es calcular la densidad de la normal ,\n",
    "# para la estimación "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.507138\n",
       "1      0.662462\n",
       "2      0.511633\n",
       "3      0.742347\n",
       "4      0.197280\n",
       "5      0.883787\n",
       "6      1.499459\n",
       "7      0.861323\n",
       "8      1.041328\n",
       "9      1.454380\n",
       "10     1.266245\n",
       "11     0.646352\n",
       "12    -0.721321\n",
       "13     0.821731\n",
       "14    -0.281541\n",
       "15     0.714687\n",
       "16     1.182864\n",
       "17     0.441411\n",
       "18     1.131758\n",
       "19     0.968541\n",
       "20     0.513914\n",
       "21     1.286568\n",
       "22     0.833590\n",
       "23     0.773237\n",
       "24    -0.266122\n",
       "25     1.724050\n",
       "26     0.540537\n",
       "27     1.010534\n",
       "28     0.578103\n",
       "29     0.203315\n",
       "         ...   \n",
       "723    1.205732\n",
       "724   -0.900731\n",
       "725   -0.644968\n",
       "726   -0.589577\n",
       "727   -0.277831\n",
       "728   -0.657508\n",
       "729   -0.275200\n",
       "730   -0.008761\n",
       "731   -0.669516\n",
       "732    0.738655\n",
       "733    1.194505\n",
       "734   -0.196259\n",
       "735   -0.126004\n",
       "736    0.656693\n",
       "737    0.584075\n",
       "738   -0.105116\n",
       "739   -0.528759\n",
       "740    0.366850\n",
       "741   -0.365979\n",
       "742   -0.279881\n",
       "743   -0.077434\n",
       "744    0.511708\n",
       "745   -1.265653\n",
       "746   -0.751095\n",
       "747    0.409358\n",
       "748    0.160233\n",
       "749   -0.189380\n",
       "750   -0.088194\n",
       "751   -0.205007\n",
       "752    0.362382\n",
       "Length: 753, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg3.params[0]+ reg3.params[1]*df1.nwifeinc +df1.educ*reg3.params[2]+ df1.exper*reg3.params[3] +df1.expersq*reg3.params[4]+ df1.age*reg3.params[5]+df1.kidslt6* reg3.params[6]+ df1.kidsge6*reg3.params[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.507138\n",
       "1      0.662462\n",
       "2      0.511633\n",
       "3      0.742347\n",
       "4      0.197280\n",
       "5      0.883787\n",
       "6      1.499459\n",
       "7      0.861323\n",
       "8      1.041328\n",
       "9      1.454380\n",
       "10     1.266245\n",
       "11     0.646352\n",
       "12    -0.721321\n",
       "13     0.821731\n",
       "14    -0.281541\n",
       "15     0.714687\n",
       "16     1.182864\n",
       "17     0.441411\n",
       "18     1.131758\n",
       "19     0.968541\n",
       "20     0.513914\n",
       "21     1.286568\n",
       "22     0.833590\n",
       "23     0.773237\n",
       "24    -0.266122\n",
       "25     1.724050\n",
       "26     0.540537\n",
       "27     1.010534\n",
       "28     0.578103\n",
       "29     0.203315\n",
       "         ...   \n",
       "723    1.205732\n",
       "724   -0.900731\n",
       "725   -0.644968\n",
       "726   -0.589577\n",
       "727   -0.277831\n",
       "728   -0.657508\n",
       "729   -0.275200\n",
       "730   -0.008761\n",
       "731   -0.669516\n",
       "732    0.738655\n",
       "733    1.194505\n",
       "734   -0.196259\n",
       "735   -0.126004\n",
       "736    0.656693\n",
       "737    0.584075\n",
       "738   -0.105116\n",
       "739   -0.528759\n",
       "740    0.366850\n",
       "741   -0.365980\n",
       "742   -0.279881\n",
       "743   -0.077434\n",
       "744    0.511708\n",
       "745   -1.265653\n",
       "746   -0.751095\n",
       "747    0.409358\n",
       "748    0.160233\n",
       "749   -0.189380\n",
       "750   -0.088194\n",
       "751   -0.205007\n",
       "752    0.362382\n",
       "Length: 753, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg3.fittedvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.35080203, 0.32034196, 0.34999988, 0.30286201, 0.39125403,\n",
       "       0.2699609 , 0.12962281, 0.27530468, 0.23197608, 0.13854661,\n",
       "       0.17895398, 0.32373702, 0.30755825, 0.28463173, 0.38344037,\n",
       "       0.3090269 , 0.1981914 , 0.36190979, 0.21026714, 0.24958043,\n",
       "       0.34959074, 0.1743716 , 0.28185162, 0.29585481, 0.38506278,\n",
       "       0.09025528, 0.34471789, 0.2394218 , 0.33755053, 0.39078137,\n",
       "       0.23698705, 0.39299403, 0.13579677, 0.3774447 , 0.07237266,\n",
       "       0.3241285 , 0.28101021, 0.23682033, 0.21661496, 0.07504805,\n",
       "       0.33202262, 0.39769328, 0.3776236 , 0.39250457, 0.27428417,\n",
       "       0.34866801, 0.31442274, 0.19956963, 0.36281415, 0.26053149,\n",
       "       0.37832979, 0.33002164, 0.14898143, 0.39893438, 0.30182584,\n",
       "       0.12317706, 0.24004431, 0.1308542 , 0.24964898, 0.37186876,\n",
       "       0.14632107, 0.33794089, 0.38962729, 0.3249627 , 0.25578178,\n",
       "       0.35659959, 0.17494131, 0.24534318, 0.354821  , 0.28071837,\n",
       "       0.20306492, 0.39832749, 0.38881952, 0.28861066, 0.14443468,\n",
       "       0.27224399, 0.38731941, 0.09799384, 0.37788608, 0.25614865,\n",
       "       0.39802465, 0.29256864, 0.3980661 , 0.35521767, 0.30848893,\n",
       "       0.14648214, 0.30737706, 0.32825852, 0.3942182 , 0.39504843,\n",
       "       0.27595129, 0.30854642, 0.37356479, 0.38173909, 0.15075699,\n",
       "       0.20720073, 0.22126247, 0.38408765, 0.3894139 , 0.39299042,\n",
       "       0.39876573, 0.23633668, 0.30461036, 0.39497185, 0.36126998,\n",
       "       0.29992335, 0.27950931, 0.20709362, 0.2416458 , 0.39546519,\n",
       "       0.38361224, 0.24241393, 0.23669015, 0.36594015, 0.36428608,\n",
       "       0.32191414, 0.2306029 , 0.38380566, 0.18357283, 0.38056995,\n",
       "       0.35686275, 0.17897999, 0.39517681, 0.2409896 , 0.33063461,\n",
       "       0.1498497 , 0.38437765, 0.34989677, 0.35537655, 0.39379115,\n",
       "       0.29426252, 0.17714066, 0.25892759, 0.33134739, 0.31735205,\n",
       "       0.369056  , 0.39028941, 0.30425094, 0.33410303, 0.29103497,\n",
       "       0.33351647, 0.10303034, 0.09369175, 0.24897455, 0.3426548 ,\n",
       "       0.3866839 , 0.36559523, 0.23420117, 0.3670594 , 0.0910707 ,\n",
       "       0.15522525, 0.33697874, 0.39267351, 0.33514688, 0.38247507,\n",
       "       0.3930058 , 0.38881501, 0.08492076, 0.16479073, 0.22532996,\n",
       "       0.15564083, 0.21544865, 0.07597266, 0.36716926, 0.25101353,\n",
       "       0.38868487, 0.09524586, 0.33949194, 0.39419755, 0.19058301,\n",
       "       0.38550795, 0.33040142, 0.19663983, 0.36009022, 0.22114487,\n",
       "       0.29674761, 0.20527152, 0.18203209, 0.37207264, 0.39638539,\n",
       "       0.23124148, 0.37424927, 0.32820195, 0.28488941, 0.38964554,\n",
       "       0.37248659, 0.10578178, 0.35651534, 0.29655583, 0.21460022,\n",
       "       0.35392658, 0.30587247, 0.36950907, 0.24536394, 0.36468196,\n",
       "       0.37440425, 0.12890679, 0.38629866, 0.28435888, 0.38975327,\n",
       "       0.3784782 , 0.38970705, 0.13605267, 0.39705439, 0.23973376,\n",
       "       0.30527296, 0.30282749, 0.14639817, 0.35683702, 0.30758872,\n",
       "       0.24411799, 0.3801788 , 0.34927148, 0.38924348, 0.24685134,\n",
       "       0.33108717, 0.2964051 , 0.16434255, 0.2085519 , 0.20994871,\n",
       "       0.22324067, 0.39860502, 0.39879358, 0.27668252, 0.16932822,\n",
       "       0.30481747, 0.38974248, 0.39121579, 0.3292462 , 0.37545228,\n",
       "       0.26301441, 0.37547708, 0.38294473, 0.35298758, 0.13887511,\n",
       "       0.39706391, 0.18792578, 0.36059692, 0.18982694, 0.19216448,\n",
       "       0.29022394, 0.17925938, 0.21667213, 0.36524995, 0.37730453,\n",
       "       0.39561899, 0.39890429, 0.37823841, 0.29547665, 0.33789363,\n",
       "       0.29340606, 0.28876534, 0.25431309, 0.30150438, 0.26684486,\n",
       "       0.37964153, 0.38452415, 0.39288441, 0.39724422, 0.28102847,\n",
       "       0.22285476, 0.30126074, 0.18828581, 0.37171898, 0.39834967,\n",
       "       0.37692124, 0.39208383, 0.38704774, 0.39395725, 0.3943518 ,\n",
       "       0.26921321, 0.37800366, 0.39613116, 0.27870786, 0.39608875,\n",
       "       0.19341923, 0.26756184, 0.39883158, 0.17403247, 0.09350184,\n",
       "       0.1632683 , 0.35394979, 0.35415779, 0.38531688, 0.2654883 ,\n",
       "       0.35604173, 0.3977213 , 0.14431451, 0.25137002, 0.32104762,\n",
       "       0.17490126, 0.14812112, 0.28532828, 0.27572991, 0.21226951,\n",
       "       0.27418854, 0.16724059, 0.25552628, 0.27847601, 0.04861435,\n",
       "       0.20471093, 0.16098443, 0.3906105 , 0.10131946, 0.37853577,\n",
       "       0.34063229, 0.21088265, 0.30897344, 0.39700384, 0.37517599,\n",
       "       0.26922834, 0.1658584 , 0.17851583, 0.25950601, 0.12162988,\n",
       "       0.38366657, 0.2883351 , 0.39782367, 0.39893835, 0.31081159,\n",
       "       0.36824712, 0.37441105, 0.39165014, 0.3277157 , 0.1502333 ,\n",
       "       0.36618905, 0.38295062, 0.39073889, 0.30615316, 0.16292871,\n",
       "       0.15030246, 0.09927356, 0.30410575, 0.338764  , 0.37765614,\n",
       "       0.12893666, 0.34425766, 0.38610508, 0.15102803, 0.28319337,\n",
       "       0.3623559 , 0.38186957, 0.16608804, 0.29410355, 0.08827131,\n",
       "       0.39875311, 0.19269854, 0.29297418, 0.2050181 , 0.20489441,\n",
       "       0.26326185, 0.39506374, 0.36998443, 0.14929091, 0.28877397,\n",
       "       0.39050231, 0.12413138, 0.38952394, 0.31399066, 0.18687087,\n",
       "       0.3775428 , 0.29386746, 0.33164803, 0.39262158, 0.20998909,\n",
       "       0.36493304, 0.34425827, 0.2389555 , 0.20814769, 0.31228105,\n",
       "       0.19558664, 0.38938329, 0.17329626, 0.32862574, 0.39879532,\n",
       "       0.34472426, 0.39877385, 0.1716425 , 0.3084399 , 0.38354308,\n",
       "       0.158648  , 0.23678263, 0.14133237, 0.2333315 , 0.13152218,\n",
       "       0.26597346, 0.38989352, 0.37012065, 0.1338493 , 0.18279207,\n",
       "       0.3423085 , 0.08608856, 0.39433368, 0.36841155, 0.30266724,\n",
       "       0.38313023, 0.39891921, 0.10101599, 0.36279556, 0.39655962,\n",
       "       0.3844539 , 0.10161451, 0.26681689, 0.38293333, 0.22683272,\n",
       "       0.14911557, 0.24522738, 0.33093613, 0.15508413, 0.36962817,\n",
       "       0.16804945, 0.3945169 , 0.16091157, 0.17840563, 0.3985428 ,\n",
       "       0.2521042 , 0.3124286 , 0.39222266, 0.12439046, 0.39867126,\n",
       "       0.36305196, 0.31278762, 0.38734014, 0.39592455, 0.1829463 ,\n",
       "       0.16886126, 0.19389964, 0.2732576 , 0.3064086 , 0.3183345 ,\n",
       "       0.37887071, 0.35340976, 0.36115996, 0.39842575, 0.37219301,\n",
       "       0.34163384, 0.32193622, 0.39884612, 0.26311873, 0.26030605,\n",
       "       0.18026201, 0.3383165 , 0.12307771, 0.39243691, 0.39576846,\n",
       "       0.36724524, 0.23384721, 0.36108313, 0.29069768, 0.39199323,\n",
       "       0.34573528, 0.35070817, 0.33827577, 0.38673867, 0.3988421 ,\n",
       "       0.39892617, 0.37704657, 0.39866885, 0.21987269, 0.38938318,\n",
       "       0.39179286, 0.21996283, 0.33321457, 0.3686501 , 0.27390989,\n",
       "       0.39881756, 0.3862494 , 0.39637599, 0.37851139, 0.14767133,\n",
       "       0.38557945, 0.395931  , 0.21268343, 0.29202339, 0.15686531,\n",
       "       0.25388384, 0.39787112, 0.39890101, 0.37536696, 0.37957087,\n",
       "       0.39691136, 0.39869528, 0.13074272, 0.00866585, 0.10458476,\n",
       "       0.30705752, 0.09171872, 0.37026239, 0.24606294, 0.32059359,\n",
       "       0.27685986, 0.27918197, 0.39892354, 0.32103522, 0.36465044,\n",
       "       0.33888147, 0.14427897, 0.19496458, 0.38818618, 0.38428014,\n",
       "       0.31042249, 0.19468674, 0.30652743, 0.22160572, 0.2950159 ,\n",
       "       0.27931284, 0.37432394, 0.38169445, 0.33559149, 0.32145746,\n",
       "       0.22705416, 0.30058834, 0.39790915, 0.08727226, 0.35357387,\n",
       "       0.28412903, 0.33235476, 0.27053505, 0.35104371, 0.34064201,\n",
       "       0.38837639, 0.23499945, 0.35283618, 0.39531564, 0.35895631,\n",
       "       0.24830387, 0.38064215, 0.24315627, 0.31126632, 0.35242794,\n",
       "       0.00768972, 0.21082172, 0.32025899, 0.39843222, 0.39463878,\n",
       "       0.2394713 , 0.2853906 , 0.39778474, 0.34752455, 0.39754609,\n",
       "       0.39886966, 0.39865727, 0.27683145, 0.3970284 , 0.35964452,\n",
       "       0.3976984 , 0.32384053, 0.29967545, 0.39238468, 0.38898735,\n",
       "       0.29747677, 0.26816054, 0.11252909, 0.27736739, 0.39289696,\n",
       "       0.38254197, 0.35478009, 0.27599522, 0.30405825, 0.39886355,\n",
       "       0.35311695, 0.04989691, 0.38887577, 0.3647939 , 0.39883501,\n",
       "       0.3989297 , 0.26056266, 0.36726663, 0.37245314, 0.34245378,\n",
       "       0.39557113, 0.35382815, 0.27115806, 0.39849017, 0.33953183,\n",
       "       0.31224886, 0.33875818, 0.38365014, 0.23265994, 0.10481247,\n",
       "       0.30510938, 0.37100057, 0.32276045, 0.28613924, 0.31626604,\n",
       "       0.03835427, 0.30520011, 0.3634417 , 0.39522216, 0.38124262,\n",
       "       0.14929216, 0.39893446, 0.09284381, 0.19355065, 0.31689788,\n",
       "       0.03730191, 0.38684524, 0.39852529, 0.3229437 , 0.3218596 ,\n",
       "       0.31284576, 0.29584163, 0.37164345, 0.31684086, 0.03713705,\n",
       "       0.39544994, 0.33154371, 0.37723489, 0.39883876, 0.39826529,\n",
       "       0.31381749, 0.39526457, 0.34718556, 0.31030572, 0.38603037,\n",
       "       0.35549497, 0.14379214, 0.22066541, 0.16251018, 0.32528686,\n",
       "       0.0967723 , 0.35638849, 0.35109684, 0.28110932, 0.39856296,\n",
       "       0.37169759, 0.27145683, 0.37069164, 0.12642106, 0.26967581,\n",
       "       0.36279962, 0.28192854, 0.33081159, 0.3144657 , 0.39824766,\n",
       "       0.28937679, 0.32777007, 0.39791972, 0.35919362, 0.09677888,\n",
       "       0.10995524, 0.20699914, 0.14434787, 0.29221075, 0.37467742,\n",
       "       0.34441742, 0.2105259 , 0.33040097, 0.2227647 , 0.0667103 ,\n",
       "       0.38558203, 0.3844614 , 0.32792332, 0.37412034, 0.31121735,\n",
       "       0.35322566, 0.19538461, 0.27669097, 0.38751322, 0.28899094,\n",
       "       0.25020156, 0.3904699 , 0.39608327, 0.33064512, 0.39579359,\n",
       "       0.38508929, 0.27062428, 0.31126684, 0.34590197, 0.36497701,\n",
       "       0.37646748, 0.39476653, 0.35581495, 0.39857231, 0.22657394,\n",
       "       0.25727478, 0.03536272, 0.39138257, 0.37135241, 0.29834536,\n",
       "       0.38370337, 0.36336747, 0.38921895, 0.38755397, 0.36121839,\n",
       "       0.33182331, 0.3919009 , 0.25907231, 0.05745909, 0.34541268,\n",
       "       0.39675897, 0.16764564, 0.32240836, 0.36287968, 0.37820544,\n",
       "       0.27943084, 0.28466375, 0.26824941, 0.3622208 , 0.36984673,\n",
       "       0.3684079 , 0.36860589, 0.398584  , 0.25963861, 0.39493945,\n",
       "       0.39092519, 0.18363943, 0.39657511, 0.3670265 , 0.28002205,\n",
       "       0.3490911 , 0.35130931, 0.34828621, 0.22992351, 0.04821202,\n",
       "       0.38295138, 0.39319345, 0.39421143, 0.15124981, 0.30558932,\n",
       "       0.37538977, 0.3081623 , 0.3708498 , 0.19285172, 0.26591009,\n",
       "       0.32402628, 0.33529675, 0.38383839, 0.32139094, 0.3841178 ,\n",
       "       0.39892697, 0.31884048, 0.30369103, 0.19546779, 0.39133261,\n",
       "       0.39578779, 0.32156307, 0.33638116, 0.39674431, 0.34689551,\n",
       "       0.37298091, 0.37309991, 0.38361902, 0.39774803, 0.34998634,\n",
       "       0.17908811, 0.30089014, 0.36687817, 0.39385368, 0.39185204,\n",
       "       0.39739375, 0.39064641, 0.37358901])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "norm.pdf(reg3.fittedvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Probit Marginal Effects       \n",
      "=====================================\n",
      "Dep. Variable:                   inlf\n",
      "Method:                          dydx\n",
      "At:                           overall\n",
      "==============================================================================\n",
      "                dy/dx    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "nwifeinc      -0.0036      0.001     -2.509      0.012      -0.006      -0.001\n",
      "educ           0.0394      0.007      5.452      0.000       0.025       0.054\n",
      "exper          0.0371      0.005      7.200      0.000       0.027       0.047\n",
      "expersq       -0.0006      0.000     -3.205      0.001      -0.001      -0.000\n",
      "age           -0.0159      0.002     -6.739      0.000      -0.021      -0.011\n",
      "kidslt6       -0.2612      0.032     -8.197      0.000      -0.324      -0.199\n",
      "kidsge6        0.0108      0.013      0.829      0.407      -0.015       0.036\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "margeffP = reg3.get_margeff()\n",
    "print(margeffP.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Probit Marginal Effects       \n",
      "=====================================\n",
      "Dep. Variable:                   inlf\n",
      "Method:                          dydx\n",
      "At:                              mean\n",
      "==============================================================================\n",
      "                dy/dx    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "nwifeinc      -0.0047      0.002     -2.484      0.013      -0.008      -0.001\n",
      "educ           0.0511      0.010      5.186      0.000       0.032       0.070\n",
      "exper          0.0482      0.007      6.575      0.000       0.034       0.063\n",
      "expersq       -0.0007      0.000     -3.141      0.002      -0.001      -0.000\n",
      "age           -0.0206      0.003     -6.241      0.000      -0.027      -0.014\n",
      "kidslt6       -0.3392      0.046     -7.316      0.000      -0.430      -0.248\n",
      "kidsge6        0.0141      0.017      0.828      0.408      -0.019       0.047\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "margeffP1 = reg3.get_margeff(at='mean')\n",
    "print(margeffP1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo 17.2 La oferta laboral anual de las mujeres casadas* (mroz.dta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tobit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El archivo MROZ incluye datos sobre las horas trabajadas de 753 mujeres casadas, 428 de las cuales trabajaron por un salario fuera del hogar durante el año; 325 de las mujeres trabajaron cero horas. Para las mujeres que trabajaron horas positivas, el rango es muy amplio, que va de 12 a 4,950. \n",
    "\n",
    "Por tanto, las horas anuales trabajadas es un buen candidato para un modelo Tobit. También se estima un modelo lineal\n",
    "(usando todas las 753 observaciones) mediante MCO. Los resultados se dan en la tabla 17.2.\n",
    "\n",
    "Esta tabla tiene varias características notorias. Primero, las estimaciones Tobit de los coeficientes tienen el mismo signo que las estimaciones de MCO correspondientes y su significancia estadística es similar.\n",
    "\n",
    "(Las posibles excepciones son los coeficientes de nwifeinc y kidsge6, pero los estadísticos t tienen magnitudes similares.) Segundo, aunque es tentador comparar las magnitudes de las estimaciones de MCO y de Tobit, esto no es muy informativo. Es necesario tener cuidado en no pensar que, debido a que el coeficiente Tobit en kidslt6 es aproximadamente el doble que el coeficiente de MCO, el modelo Tobit implica una respuesta mucho mayor de horas trabajadas respecto a los niños pequeños.\n",
    "\n",
    "Se pueden multiplicar las estimaciones Tobit mediante los factores adecuados de ajuste para hacerlas aproximadamente comparables a las estimaciones de MCO. El factor escalar EPP $n^{-1} \\sum_{i-1}^{n} \\Phi(x_{i}\\hat \\beta /\\hat \\sigma)$ resulta ser de cerca de 0.589, el cual se puede usar para obtener los efectos parciales promedio para la estimación Tobit. \n",
    "\n",
    "Si, por ejemplo, se multiplica el coeficiente de educ por 0.589 se obtiene 0.589(80.65) $\\sim$ 47.50 (es decir, 47.5 horas más), lo cual es un poco mayor que el efecto parcial de MCO, de aproximadamente 28.8 horas. Así que, incluso para estimar un efecto promedio, las estimaciones Tobit son notablemente mayores en magnitud que la estimación de MCO correspondiente. \n",
    "\n",
    "Si, en lugar de ello, se desea el efecto estimado de otro año de educación a partir de los valores promedio de todas las variables explicativas, entonces se\n",
    "calcula el factor escalar EPA $\\Phi(\\bar x_{i}\\hat \\beta /\\hat \\sigma)$. Éste resulta ser de aproximadamente 0.645 [cuando se usa el promedio cuadrado de la experiencia, $(\\overline exper)^{2}$, en lugar del promedio de $exper^{2}$]. Este efecto parcial, que es de aproximadamente 52 horas, es casi el doble de la estimación de MCO. Con excepción de kidsge6, los coeficientes de pendiente escalados de Tobit son todos mayores en magnitud que el coeficiente correspondiente de MCO.\n",
    "\n",
    "Se ha reportado una R-cuadrada tanto para el modelo Tobit como para el de regresión lineal. La R-cuadrada para MCO es la acostumbrada. Para Tobit, la R-cuadrada es el coeficiente de correlación entre $y_{i}$ y $\\hat y_{i}$, donde $\\hat y{i} = \\Phi(x_{i} \\hat \\beta /\\hat \\sigma) x_{i} \\hat \\beta + \\hat \\sigma \\phi(x_{i} \\hat \\beta /\\hat \\sigma)$ es la estimación de $E(y|x = x_{i})$. Esto está motivado por el hecho de que la R-cuadrada acostumbrada para MCO es igual a la correlación cuadrada entre $y_{i}$ y los valores ajustados [vea la ecuación (3.29)]. En los modelos no lineales como el modelo Tobit, el coeficiente de correlación cuadrada no es idéntico a una R-cuadrada basado en una suma de residuales cuadrados como en\n",
    "(3.28). Esto es debido a que los valores ajustados, como se definieron antes, y los residuales, $y_{i} - \\hat y_{i}$, están\n",
    "correlacionados en la muestra. Una R-cuadrada definida como el coeficiente de correlación cuadrado entre\n",
    "$y_{i}$ y $\\hat y_{i}$ tiene la ventaja de siempre estar entre cero y uno; una R-cuadrada basada en la suma de los residuales\n",
    "cuadrados no necesita tener esta característica.\n",
    "\n",
    "Se puede ver que, con base en las medidas de R-cuadrada, la función de media condicional Tobit encaja un poco mejor con los datos de las horas, pero no es una mejora sustancial. No obstante, se debe recordar que las estimaciones Tobit no se eligen para maximizar una R-cuadrada (maximizan la función de log-verosimilitud), mientras que las estimaciones de MCO son los valores que producen la R-cuadrada más alta dada la forma funcional lineal.\n",
    "\n",
    "Por construcción, todos los valores ajustados Tobit para hours son positivos. En contrate, 39 de los\n",
    "valores ajustados por MCO son negativos. Aunque las predicciones negativas son de algún interés, 39 de\n",
    "753 sólo está por encima de 5% de las observaciones. No es completamente claro cómo se traducen los\n",
    "valores ajustados negativos de MCO a las diferencias en los efectos parciales estimados. \n",
    "\n",
    "La figura 17.3 presenta la gráfica de las estimaciones de $E(hours|x) en función de la educación; para el modelo Tobit,\n",
    "las demás variables explicativas se establecen en sus valores promedio. Para el modelo lineal, la ecuación\n",
    "graficada es \n",
    "\n",
    "$\\widehat{hours} = 387.19 + 28.76 educ$. Para el modelo Tobit, la ecuación graficada es $\\widehat{hours} = \\Phi[(-694.12 + 80.65 educ)/1,122.02] (-694.12 + 80.65 educ) + 1,122.02 \\phi[(-694.12 + 80.65 educ)/1,122.02]$. \n",
    "\n",
    "Como se puede ver en la figura, el modelo lineal da estimaciones notablemente superiores de las horas trabajadas esperadas incluso para niveles muy altos de educación. \n",
    "\n",
    "Por ejemplo, a los ocho años de educación, el valor predicho por MCO de las horas es de cerca de 617.5, mientras que la estimación Tobit es de aproximadamente 423.9. A los 12 años de educación, las horas predichas son de cerca de 732.7\n",
    "y 598.3, respectivamente. Las dos líneas de predicción cruzan después de los 17 años de educación, pero ninguna mujer en la muestra tiene más de 17 años de educación. La pendiente creciente de la línea Tobit indica con claridad el creciente efecto marginal de la educación sobre las horas trabajadas esperadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  hours   R-squared:                       0.266\n",
      "Model:                            OLS   Adj. R-squared:                  0.259\n",
      "Method:                 Least Squares   F-statistic:                     38.50\n",
      "Date:                Tue, 10 Oct 2023   Prob (F-statistic):           3.42e-46\n",
      "Time:                        01:36:09   Log-Likelihood:                -6049.5\n",
      "No. Observations:                 753   AIC:                         1.212e+04\n",
      "Df Residuals:                     745   BIC:                         1.215e+04\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept   1330.4824    270.785      4.913      0.000     798.891    1862.074\n",
      "nwifeinc      -3.4466      2.544     -1.355      0.176      -8.441       1.548\n",
      "educ          28.7611     12.955      2.220      0.027       3.329      54.193\n",
      "exper         65.6725      9.963      6.592      0.000      46.114      85.231\n",
      "expersq       -0.7005      0.325     -2.158      0.031      -1.338      -0.063\n",
      "age          -30.5116      4.364     -6.992      0.000     -39.079     -21.945\n",
      "kidslt6     -442.0899     58.847     -7.513      0.000    -557.615    -326.565\n",
      "kidsge6      -32.7792     23.176     -1.414      0.158     -78.278      12.719\n",
      "==============================================================================\n",
      "Omnibus:                       79.794   Durbin-Watson:                   1.371\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              112.876\n",
      "Skew:                           0.779   Prob(JB):                     3.08e-25\n",
      "Kurtosis:                       4.083   Cond. No.                     3.06e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 3.06e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "regEj172 = smf.ols('hours ~ nwifeinc + educ + exper + expersq +age+kidslt6+ kidsge6', data = df1).fit()\n",
    "print(regEj172.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py4etrics.truncreg import Truncreg\n",
    "from py4etrics.tobit import Tobit\n",
    "from py4etrics.heckit import Heckit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "censor = df1['hours'].apply(lambda x: -1 if x==left else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 5.071839\n",
      "         Iterations: 2418\n",
      "         Function evaluations: 3520\n",
      "                              Tobit Regression Results                             \n",
      "===================================================================================\n",
      "Dep. Variable:                       hours   Pseudo R-squ:                    0.034\n",
      "Method:                 Maximum Likelihood   Log-Likelihood:                -3819.1\n",
      "No. Observations:                      753   LL-Null:                       -3954.9\n",
      "No. Uncensored Obs:                    428   LL-Ratio:                        271.6\n",
      "No. Left-censored Obs:                 325   LLR p-value:                     0.000\n",
      "No. Right-censored Obs:                  0   AIC:                            7654.2\n",
      "Df Residuals:                          745   BIC:                            7691.2\n",
      "Df Model:                                7   Covariance Type:             nonrobust\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept    965.3054    446.431      2.162      0.031      90.317    1840.294\n",
      "nwifeinc      -8.8142      4.459     -1.977      0.048     -17.554      -0.075\n",
      "educ          80.6456     21.583      3.736      0.000      38.343     122.948\n",
      "exper        131.5643     17.279      7.614      0.000      97.697     165.431\n",
      "expersq       -1.8642      0.538     -3.467      0.001      -2.918      -0.810\n",
      "age          -54.4050      7.418     -7.334      0.000     -68.945     -39.865\n",
      "kidslt6     -894.0217    111.878     -7.991      0.000   -1113.299    -674.745\n",
      "kidsge6      -16.2180     38.640     -0.420      0.675     -91.950      59.514\n",
      "Log(Sigma)     7.0229      0.037    189.514      0.000       6.950       7.096\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "regEj172T = Tobit.from_formula('hours ~1+ nwifeinc + educ + exper + expersq +age+kidslt6+ kidsge6',cens=censor,left=0, data = df1).fit()\n",
    "print(regEj172T.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo 17.3 Modelo de regresión de Poisson para el número de detenciones (crime1.dta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>narr86</th>\n",
       "      <th>nfarr86</th>\n",
       "      <th>nparr86</th>\n",
       "      <th>pcnv</th>\n",
       "      <th>avgsen</th>\n",
       "      <th>tottime</th>\n",
       "      <th>ptime86</th>\n",
       "      <th>qemp86</th>\n",
       "      <th>inc86</th>\n",
       "      <th>durat</th>\n",
       "      <th>black</th>\n",
       "      <th>hispan</th>\n",
       "      <th>born60</th>\n",
       "      <th>pcnvsq</th>\n",
       "      <th>pt86sq</th>\n",
       "      <th>inc86sq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>17.600000</td>\n",
       "      <td>35.200001</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>144</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1936</td>\n",
       "      <td>0</td>\n",
       "      <td>0.640000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>22.799999</td>\n",
       "      <td>22.799999</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1089</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>25</td>\n",
       "      <td>77.440002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>65.610008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   narr86  nfarr86  nparr86  pcnv     avgsen    tottime  ptime86  qemp86  \\\n",
       "0       0        0        0  0.38  17.600000  35.200001       12     0.0   \n",
       "1       2        2        0  0.44   0.000000   0.000000        0     1.0   \n",
       "2       1        1        0  0.33  22.799999  22.799999        0     0.0   \n",
       "3       2        2        1  0.25   0.000000   0.000000        5     2.0   \n",
       "4       1        1        0  0.00   0.000000   0.000000        0     2.0   \n",
       "\n",
       "   inc86  durat  black  hispan  born60  pcnvsq  pt86sq    inc86sq  \n",
       "0    0.0    0.0      0       0       1  0.1444     144   0.000000  \n",
       "1    0.8    0.0      0       1       0  0.1936       0   0.640000  \n",
       "2    0.0   11.0      1       0       1  0.1089       0   0.000000  \n",
       "3    8.8    0.0      0       1       1  0.0625      25  77.440002  \n",
       "4    8.1    1.0      0       0       0  0.0000       0  65.610008  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfej17_3 = pd.read_stata('crime1.dta')\n",
    "dfej17_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table_lin: \n",
      "                b      se        t    pval\n",
      "Intercept  0.5766  0.0379  15.2150  0.0000\n",
      "pcnv      -0.1319  0.0404  -3.2642  0.0011\n",
      "avgsen    -0.0113  0.0122  -0.9257  0.3547\n",
      "tottime    0.0121  0.0094   1.2790  0.2010\n",
      "ptime86   -0.0409  0.0088  -4.6378  0.0000\n",
      "qemp86    -0.0513  0.0145  -3.5420  0.0004\n",
      "inc86     -0.0015  0.0003  -4.2613  0.0000\n",
      "black      0.3270  0.0454   7.1987  0.0000\n",
      "hispan     0.1938  0.0397   4.8799  0.0000\n",
      "born60    -0.0225  0.0333  -0.6747  0.4999\n",
      "\n",
      "table_poisson: \n",
      "                b      se       t    pval\n",
      "Intercept -0.5996  0.0673 -8.9158  0.0000\n",
      "pcnv      -0.4016  0.0850 -4.7260  0.0000\n",
      "avgsen    -0.0238  0.0199 -1.1918  0.2333\n",
      "tottime    0.0245  0.0148  1.6603  0.0969\n",
      "ptime86   -0.0986  0.0207 -4.7625  0.0000\n",
      "qemp86    -0.0380  0.0290 -1.3099  0.1902\n",
      "inc86     -0.0081  0.0010 -7.7624  0.0000\n",
      "black      0.6608  0.0738  8.9503  0.0000\n",
      "hispan     0.4998  0.0739  6.7609  0.0000\n",
      "born60    -0.0510  0.0641 -0.7967  0.4256\n",
      "\n",
      "table_qpoisson: \n",
      "                b      se       t    pval\n",
      "Intercept -0.5996  0.0828 -7.2393  0.0000\n",
      "pcnv      -0.4016  0.1046 -3.8373  0.0001\n",
      "avgsen    -0.0238  0.0246 -0.9677  0.3332\n",
      "tottime    0.0245  0.0182  1.3481  0.1776\n",
      "ptime86   -0.0986  0.0255 -3.8670  0.0001\n",
      "qemp86    -0.0380  0.0357 -1.0636  0.2875\n",
      "inc86     -0.0081  0.0013 -6.3028  0.0000\n",
      "black      0.6608  0.0909  7.2673  0.0000\n",
      "hispan     0.4998  0.0910  5.4896  0.0000\n",
      "born60    -0.0510  0.0789 -0.6469  0.5177\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#import wooldridge as woo\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "#crime1 = woo.dataWoo('crime1')\n",
    "\n",
    "# estimate linear model:\n",
    "reg_lin = smf.ols(formula='narr86 ~ pcnv + avgsen + tottime + ptime86 +'\n",
    "                          'qemp86 + inc86 + black + hispan + born60',\n",
    "                  data=dfej17_3)\n",
    "results_lin = reg_lin.fit()\n",
    "\n",
    "# print regression table:\n",
    "table_lin = pd.DataFrame({'b': round(results_lin.params, 4),\n",
    "                          'se': round(results_lin.bse, 4),\n",
    "                          't': round(results_lin.tvalues, 4),\n",
    "                          'pval': round(results_lin.pvalues, 4)})\n",
    "print(f'table_lin: \\n{table_lin}\\n')\n",
    "\n",
    "# estimate Poisson model:\n",
    "reg_poisson = smf.poisson(formula='narr86 ~ pcnv + avgsen + tottime +'\n",
    "                                  'ptime86 + qemp86 + inc86 + black +'\n",
    "                                  'hispan + born60',\n",
    "                          data=dfej17_3)\n",
    "results_poisson = reg_poisson.fit(disp=0)\n",
    "\n",
    "# print regression table:\n",
    "table_poisson = pd.DataFrame({'b': round(results_poisson.params, 4),\n",
    "                              'se': round(results_poisson.bse, 4),\n",
    "                              't': round(results_poisson.tvalues, 4),\n",
    "                              'pval': round(results_poisson.pvalues, 4)})\n",
    "print(f'table_poisson: \\n{table_poisson}\\n')\n",
    "\n",
    "# estimate Quasi-Poisson model:\n",
    "reg_qpoisson = smf.glm(formula='narr86 ~ pcnv + avgsen + tottime + ptime86 +'\n",
    "                               'qemp86 + inc86 + black + hispan + born60',\n",
    "                       family=sm.families.Poisson(),\n",
    "                       data=dfej17_3)\n",
    "# the argument scale controls for the dispersion in exponential dispersion models,\n",
    "# see the module documentation for more details:\n",
    "results_qpoisson = reg_qpoisson.fit(scale='X2', disp=0)\n",
    "\n",
    "# print regression table:\n",
    "table_qpoisson = pd.DataFrame({'b': round(results_qpoisson.params, 4),\n",
    "                               'se': round(results_qpoisson.bse, 4),\n",
    "                               't': round(results_qpoisson.tvalues, 4),\n",
    "                               'pval': round(results_qpoisson.pvalues, 4)})\n",
    "print(f'table_qpoisson: \\n{table_qpoisson}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo 17.4 La duración hasta la reincidencla (recid.dta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Censurada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El archivo RECID.RAW contiene datos sobre el tiempo en meses hasta que un recluso en una prisión de\n",
    "Carolina del Norte es arrestado después de haber sido liberado de prisión: llamemos a esto durat. Algunos\n",
    "reclusos participaron en un programa laboral mientras estaban en prisión. También se controla una variedad\n",
    "de variables demográficas, así como medidas de historia criminal y de prisión.\n",
    "De 1,445 reclusos, 893 no habían sido arrestados durante el periodo de seguimiento; por tanto, estas\n",
    "observaciones están censuradas. Las duraciones censuradas difirieron entre los reclusos, con un rango de\n",
    "70 a 81 meses.\n",
    "La tabla 17.4 da los resultados de la regresión censurada normal para log(durat). Cada uno de los\n",
    "coeficientes, multiplicados por 100, dan el cambio porcentual estimado en la duración esperada dado un\n",
    "incremento ceteris paribus de una unidad en la variable explicativa correspondiente.\n",
    "Varios coeficientes en la tabla 17.4 son interesantes. Las variables priors (número de condenas anteriores)\n",
    "y tserved (meses totales pasados en prisión) tienen efectos negativos sobre el periodo que transcurre\n",
    "hasta que ocurra un nuevo arresto. Esto sugiere que estas variables miden la tendencia de la actividad criminal\n",
    "más que representar un efecto disuasivo. Por ejemplo, un recluso con una condena previa adicional\n",
    "tiene un periodo hasta el siguiente arresto que es casi 14% menor. Un año adicional de tiempo en prisión\n",
    "reduce la duración por casi 100 \u0003 12(.019) \u0002 22.8%. Un hallazgo un tanto sorprendente es que un hombre\n",
    "que purga una condena por un delito grave (felon) tiene un periodo esperado estimado que es casi 56%\n",
    "[exp(.444) \u0007 1 \u0006 .56] mayor que un hombre que purga una condena por un delito no grave.\n",
    "Aquellos que tienen una historia de abuso de drogas y alcohol tienen duraciones esperadas sustancialmente\n",
    "menores hasta el siguiente arresto. (Las variables alcohol y drugs son variables binarias.) Los\n",
    "hombres de mayor edad (age) y los hombres que estaban casados (married) al momento de su condena en\n",
    "prisión, tienen periodos esperados más largos hasta su siguiente arresto. Los hombres negros (black) tienen\n",
    "periodos sustancialmente menores del orden de 42% [exp(\u0007.543) \u0007 1 \u0006 \u0007.42].\n",
    "La variable de política clave, workprg, no tiene el efecto deseado. La estimación puntual es que, todo\n",
    "lo demás constante, los hombres que participaron en el programa laboral tienen periodos de reincidencia\n",
    "que son aproximadamente 6.3% menores que los hombres que no participaron. El coeficiente tiene un\n",
    "estadístico t pequeño, así que probablemente concluiríamos que el programa de trabajo no tiene efecto. Esto\n",
    "se puede deber a un problema de autoselección, o podría ser producto de la forma en que los hombres se\n",
    "reclutaron en el programa. Por supuesto, simplemente puede deberse a que el programa fue ineficaz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>black</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>drugs</th>\n",
       "      <th>super</th>\n",
       "      <th>married</th>\n",
       "      <th>felon</th>\n",
       "      <th>workprg</th>\n",
       "      <th>property</th>\n",
       "      <th>person</th>\n",
       "      <th>priors</th>\n",
       "      <th>educ</th>\n",
       "      <th>rules</th>\n",
       "      <th>age</th>\n",
       "      <th>tserved</th>\n",
       "      <th>follow</th>\n",
       "      <th>durat</th>\n",
       "      <th>cens</th>\n",
       "      <th>ldurat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>441</td>\n",
       "      <td>30</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>4.276666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>307</td>\n",
       "      <td>19</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>4.317488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>262</td>\n",
       "      <td>27</td>\n",
       "      <td>81</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2.197225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>253</td>\n",
       "      <td>38</td>\n",
       "      <td>76</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>3.218876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>244</td>\n",
       "      <td>4</td>\n",
       "      <td>81</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>4.394449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   black  alcohol  drugs  super  married  felon  workprg  property  person  \\\n",
       "0      0        1      0      1        1      0        1         0       0   \n",
       "1      1        0      0      1        0      1        1         1       0   \n",
       "2      0        0      0      0        0      0        1         1       0   \n",
       "3      0        0      1      1        0      1        1         1       0   \n",
       "4      0        0      1      1        0      0        0         0       0   \n",
       "\n",
       "   priors  educ  rules  age  tserved  follow  durat  cens    ldurat  \n",
       "0       0     7      2  441       30      72     72     1  4.276666  \n",
       "1       0    12      0  307       19      75     75     1  4.317488  \n",
       "2       0     9      5  262       27      81      9     0  2.197225  \n",
       "3       2     9      3  253       38      76     25     0  3.218876  \n",
       "4       0     9      0  244        4      81     81     1  4.394449  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfej17_4 = pd.read_stata('recid.dta')\n",
    "dfej17_4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\lib\\site-packages\\ipykernel_launcher.py:44: RuntimeWarning: divide by zero encountered in log\n",
      "c:\\python\\lib\\site-packages\\statsmodels\\tools\\numdiff.py:158: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  f(*((x-ei,)+args), **kwargs))/(2 * epsilon[k])\n",
      "c:\\python\\lib\\site-packages\\ipykernel_launcher.py:44: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results_censReg.summary(): \n",
      "                               CensReg Results                                \n",
      "==============================================================================\n",
      "Dep. Variable:                 ldurat   Log-Likelihood:                -1597.1\n",
      "Model:                        CensReg   AIC:                             3216.\n",
      "Method:            Maximum Likelihood   BIC:                             3274.\n",
      "Date:                Wed, 04 Oct 2023                                         \n",
      "Time:                        15:45:28                                         \n",
      "No. Observations:                1445                                         \n",
      "Df Residuals:                    1434                                         \n",
      "Df Model:                          10                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      4.0994      0.348     11.796      0.000       3.418       4.781\n",
      "workprg       -0.0626      0.120     -0.521      0.602      -0.298       0.173\n",
      "priors        -0.1373      0.021     -6.396      0.000      -0.179      -0.095\n",
      "tserved       -0.0193      0.003     -6.491      0.000      -0.025      -0.013\n",
      "felon          0.4440      0.145      3.060      0.002       0.160       0.728\n",
      "alcohol       -0.6349      0.144     -4.403      0.000      -0.918      -0.352\n",
      "drugs         -0.2982      0.133     -2.246      0.025      -0.558      -0.038\n",
      "black         -0.5427      0.117     -4.621      0.000      -0.773      -0.313\n",
      "married        0.3407      0.140      2.436      0.015       0.067       0.615\n",
      "educ           0.0229      0.025      0.902      0.367      -0.027       0.073\n",
      "age            0.0039      0.001      6.450      0.000       0.003       0.005\n",
      "par0           0.5936      0.034     17.249      0.000       0.526       0.661\n",
      "==============================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\lib\\site-packages\\statsmodels\\base\\model.py:2653: UserWarning: df_model + k_constant differs from nparams\n",
      "  warnings.warn(\"df_model + k_constant differs from nparams\")\n",
      "c:\\python\\lib\\site-packages\\statsmodels\\base\\model.py:2655: UserWarning: df_resid differs from nobs - nparams\n",
      "  warnings.warn(\"df_resid differs from nobs - nparams\")\n"
     ]
    }
   ],
   "source": [
    "#import wooldridge as woo\n",
    "import numpy as np\n",
    "import patsy as pt\n",
    "import scipy.stats as stats\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.base.model as smclass\n",
    "\n",
    "#recid = woo.dataWoo('recid')\n",
    "\n",
    "# define dummy for censored observations:\n",
    "censored = dfej17_4['cens'] != 0\n",
    "y, X = pt.dmatrices('ldurat ~ workprg + priors + tserved + felon +'\n",
    "                    'alcohol + drugs + black + married + educ + age',\n",
    "                    data=dfej17_4, return_type='dataframe')\n",
    "\n",
    "# generate starting solution:\n",
    "reg_ols = smf.ols(formula='ldurat ~ workprg + priors + tserved + felon +'\n",
    "                          'alcohol + drugs + black + married + educ + age',\n",
    "                  data=dfej17_4)\n",
    "results_ols = reg_ols.fit()\n",
    "sigma_start = np.log(sum(results_ols.resid ** 2) / len(results_ols.resid))\n",
    "params_start = np.concatenate((np.array(results_ols.params), sigma_start),\n",
    "                              axis=None)\n",
    "\n",
    "\n",
    "# extend statsmodels class by defining nloglikeobs:\n",
    "class CensReg(smclass.GenericLikelihoodModel):\n",
    "    def __init__(self, endog, cens, exog):\n",
    "        self.cens = cens\n",
    "        super(smclass.GenericLikelihoodModel, self).__init__(endog, exog,\n",
    "                                                             missing='none')\n",
    "\n",
    "    def nloglikeobs(self, params):\n",
    "        X = self.exog\n",
    "        y = self.endog\n",
    "        cens = self.cens\n",
    "        p = X.shape[1]\n",
    "        beta = params[0:p]\n",
    "        sigma = np.exp(params[p])\n",
    "        y_hat = np.dot(X, beta)\n",
    "        ll = np.empty(len(y))\n",
    "        # uncensored:\n",
    "        ll[~cens] = np.log(stats.norm.pdf((y - y_hat)[~cens] /\n",
    "                                          sigma)) - np.log(sigma)\n",
    "        # censored:\n",
    "        ll[cens] = np.log(stats.norm.cdf(-(y - y_hat)[cens] / sigma))\n",
    "        return -ll\n",
    "\n",
    "\n",
    "# results of MLE:\n",
    "reg_censReg = CensReg(endog=y, exog=X, cens=censored)\n",
    "results_censReg = reg_censReg.fit(start_params=params_start,\n",
    "                                  maxiter=10000, method='BFGS', disp=0)\n",
    "print(f'results_censReg.summary(): \\n{results_censReg.summary()}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo 17.5 Ecuación de oferta salarial para mujeres casadas* (mroz.dta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heckman as heckman\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(753, 22)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['unos']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Heckman Regression Results      \n",
      "=======================================\n",
      "Dep. Variable:                    lwage\n",
      "Model:                          Heckman\n",
      "Method:                Heckman Two-Step\n",
      "Date:                  Wed, 04 Oct 2023\n",
      "Time:                          15:21:57\n",
      "No. Total Obs.:                     753\n",
      "No. Censored Obs.:                  325\n",
      "No. Uncensored Obs.:                428\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "unos          -0.5337      0.236     -2.257      0.024      -0.997      -0.070\n",
      "educ           0.1072      0.015      7.374      0.000       0.079       0.136\n",
      "exper          0.0416      0.013      3.171      0.002       0.016       0.067\n",
      "expersq       -0.0008      0.000     -2.071      0.038      -0.002   -4.34e-05\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "nwifeinc      -0.0067      0.004     -1.666      0.096      -0.015       0.001\n",
      "age            0.0067      0.002      3.091      0.002       0.002       0.011\n",
      "kidslt6       -0.4687      0.094     -5.001      0.000      -0.652      -0.285\n",
      "kidsge6        0.0650      0.034      1.936      0.053      -0.001       0.131\n",
      "================================================================================\n",
      "                   coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "IMR (Lambda)     0.0217      0.241      0.090      0.928      -0.451       0.495\n",
      "=====================================\n",
      "rho:                            0.033\n",
      "sigma:                          0.664\n",
      "=====================================\n",
      "\n",
      "First table are the estimates for the regression (response) equation.\n",
      "Second table are the estimates for the selection equation.\n",
      "Third table is the estimate for the coef of the inverse Mills ratio (Heckman's Lambda).\n"
     ]
    }
   ],
   "source": [
    "res = heckman.Heckman(df1.lwage, df1[['unos','educ', 'exper','expersq']],df1[['nwifeinc', 'age', 'kidslt6' , 'kidsge6']]).fit(method='twostep')\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ver solomon y solucion con ratio mills como phi /Phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results_heckit.summary(): \n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  lwage   R-squared:                       0.149\n",
      "Model:                            OLS   Adj. R-squared:                  0.141\n",
      "Method:                 Least Squares   F-statistic:                     18.58\n",
      "Date:                Wed, 04 Oct 2023   Prob (F-statistic):           4.44e-14\n",
      "Time:                        15:33:10   Log-Likelihood:                -433.47\n",
      "No. Observations:                 428   AIC:                             876.9\n",
      "Df Residuals:                     423   BIC:                             897.2\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================\n",
      "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "Intercept        -0.3609      0.271     -1.332      0.184      -0.893       0.172\n",
      "educ              0.1075      0.016      6.894      0.000       0.077       0.138\n",
      "exper             0.0152      0.005      2.929      0.004       0.005       0.025\n",
      "I(exper ** 2)     0.0003      0.000      0.660      0.509      -0.001       0.001\n",
      "inv_mills        -0.0283      0.126     -0.224      0.823      -0.276       0.220\n",
      "==============================================================================\n",
      "Omnibus:                       80.915   Durbin-Watson:                   1.982\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              302.604\n",
      "Skew:                          -0.798   Prob(JB):                     1.95e-66\n",
      "Kurtosis:                       6.798   Cond. No.                         625.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "import scipy.stats as stats\n",
    "\n",
    "#mroz = woo.dataWoo('mroz')\n",
    "\n",
    "# step 1 (use all n observations to estimate a probit model of s_i on z_i):\n",
    "reg_probit = smf.probit(formula='inlf ~ educ + exper + I(exper**2) +'\n",
    "                                'nwifeinc + age + kidslt6 + kidsge6',\n",
    "                        data=df1)\n",
    "results_probit = reg_probit.fit(disp=0)\n",
    "pred_inlf = results_probit.fittedvalues\n",
    "df1['inv_mills'] = stats.norm.pdf(pred_inlf) / stats.norm.cdf(pred_inlf)\n",
    "\n",
    "# step 2 (regress y_i on x_i and inv_mills in sample selection):\n",
    "reg_heckit = smf.ols(formula='lwage ~ educ + exper + I(exper**2) + inv_mills',\n",
    "                     subset=(df1['inlf'] == 1), data=df1)\n",
    "results_heckit = reg_heckit.fit()\n",
    "\n",
    "# print results:\n",
    "print(f'results_heckit.summary(): \\n{results_heckit.summary()}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con py4etrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "endog = df1.loc[:,'lwage']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "exog = df1.loc[:,['educ', 'exper', 'expersq']]\n",
    "exog['Intercept'] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "exog_select = df1.loc[:,['educ', 'exper', 'expersq','nwifeinc', 'age', 'kidslt6', 'kidsge6', ]]\n",
    "exog_select['Intercept'] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Heckit Regression Results                            \n",
      "================================================================================\n",
      "Dep. Variable:                    lwage   R-squared:                       0.156\n",
      "Model:                           Heckit   Adj. R-squared:                  0.150\n",
      "Method:                Heckman Two-Step   F-statistics:                   26.148\n",
      "Date:                  Tue, 10 Oct 2023   Prob (F-statistic):              0.000\n",
      "Time:                          10:58:51   Cov in 1st Stage:            nonrobust\n",
      "No. Total Obs.:                     753   Cov in 2nd Stage:                  HC1\n",
      "No. Censored Obs.:                  325                                         \n",
      "No. Uncensored Obs.:                428                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "educ           0.1091      0.016      7.026      0.000       0.079       0.139\n",
      "exper          0.0439      0.016      2.699      0.007       0.012       0.076\n",
      "expersq       -0.0009      0.000     -1.957      0.050      -0.002    1.15e-06\n",
      "Intercept     -0.5781      0.305     -1.895      0.058      -1.176       0.020\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "educ           0.1309      0.025      5.183      0.000       0.081       0.180\n",
      "exper          0.1233      0.019      6.590      0.000       0.087       0.160\n",
      "expersq       -0.0019      0.001     -3.145      0.002      -0.003      -0.001\n",
      "nwifeinc      -0.0120      0.005     -2.484      0.013      -0.022      -0.003\n",
      "age           -0.0529      0.008     -6.235      0.000      -0.069      -0.036\n",
      "kidslt6       -0.8683      0.119     -7.326      0.000      -1.101      -0.636\n",
      "kidsge6        0.0360      0.043      0.828      0.408      -0.049       0.121\n",
      "Intercept      0.2701      0.509      0.531      0.595      -0.727       1.267\n",
      "================================================================================\n",
      "                   coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "IMR (Lambda)     0.0323      0.134      0.241      0.809      -0.230       0.294\n",
      "=====================================\n",
      "rho:                            0.049\n",
      "sigma:                          0.664\n",
      "=====================================\n",
      "\n",
      "First table are the estimates for the regression (response) equation.\n",
      "Second table are the estimates for the selection equation.\n",
      "Third table is the estimate for the coef of the inverse Mills ratio (Heckman's Lambda).\n"
     ]
    }
   ],
   "source": [
    "res_heckit = Heckit(endog, exog, exog_select).fit(cov_type_2='HC1')\n",
    "\n",
    "print(res_heckit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
